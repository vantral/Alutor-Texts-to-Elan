{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1be9580",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import uuid\n",
    "import jinja2\n",
    "import pathlib\n",
    "import docx\n",
    "from string import punctuation\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82624092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    lst = re.split(r'([.!?…:]+|$)', txt)\n",
    "    lst = [ ''.join(x).strip() for x in zip(lst[0::2], lst[1::2]) ]\n",
    "    while '' in lst:\n",
    "        lst.remove('')\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0003218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most(lst):\n",
    "    if sum(lst) / len(lst) > 0.5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def count_ratios(sents, pattern):\n",
    "    ratios = []\n",
    "    for sent in sents:\n",
    "        sent = sent.lower()\n",
    "        for punc in punctuation + '1234567890':\n",
    "            sent = sent.replace(punc, '')\n",
    "        sent = sent.replace(' ', '')\n",
    "        if len(sent) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            ratios.append(\n",
    "                len(pattern.findall(sent)) / len(sent)\n",
    "            )\n",
    "#     print(ratios)\n",
    "    return ratios\n",
    "\n",
    "def split_by_language(string):\n",
    "    pattern = re.compile(r'[а-яё]')\n",
    "    \n",
    "    time = re.search(r'(?:\\d\\d?:)?\\d?\\d:\\d\\d', string)\n",
    "    \n",
    "    if time:\n",
    "        spl = string.split(time.group(0))\n",
    "        comm = spl[-1]\n",
    "        string = spl[0]\n",
    "        time = ' ' + time.group(0)\n",
    "    else:\n",
    "        time = ''\n",
    "        comm = ''\n",
    "    \n",
    "    sents = tokenize(string)\n",
    "#     print(sents)\n",
    "    if len(sents) == 1:\n",
    "        return [string + time + f' COMMENT: {comm}']\n",
    "    \n",
    "    for i, sent in enumerate(sents):\n",
    "        prev_ratios = count_ratios(sents[0:i + 1], pattern)\n",
    "        next_ratios = count_ratios(sents[i + 1:], pattern)\n",
    "        \n",
    "        if all([x < 0.5 for x in prev_ratios]) and all([x > 0.6 for x in next_ratios]):\n",
    "            return [' '.join(sents[0:i + 1]), ' '.join(sents[i + 1:]) + time + f' COMMENT: {comm}']\n",
    "    return [string + time + f' COMMENT: {comm}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014f51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_by_language(text):\n",
    "    lines = []\n",
    "\n",
    "    for line in text:\n",
    "        line = split_by_language(line)\n",
    "        lines.append(line)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf980057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lines(lines):\n",
    "\n",
    "    pattern = re.compile(r'(?:\\d\\d?:)?\\d?\\d:\\d\\d')\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for group in lines:\n",
    "        start = 0\n",
    "        mini_df = []\n",
    "        for i, line in enumerate(group):\n",
    "            data = {}\n",
    "            if 'COMMENT:' in line:\n",
    "                splitted = line.split('COMMENT: ')\n",
    "                line = splitted[0].strip()\n",
    "                group[i] = line\n",
    "                comm = splitted[1]\n",
    "                if comm.strip():\n",
    "                    data['comment'] = comm.strip()\n",
    "            time = pattern.search(line)\n",
    "            if time:\n",
    "                data['time'] = time.group(0)\n",
    "                split = pattern.split(line)\n",
    "                if len(''.join(split).strip()) > 3:\n",
    "                    data['text'] = group[start:i] + [split[0].strip()]\n",
    "                else:\n",
    "                    data['text'] = group[start:i]\n",
    "                start = i + 1\n",
    "                mini_df.append(data)\n",
    "        if not mini_df:\n",
    "            mini_df.append({\n",
    "                'time': 'UNK',\n",
    "                'text': group\n",
    "            })\n",
    "        df.extend(mini_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49922a03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_problem_parts(df):\n",
    "    for part in df:\n",
    "        if len(part['text']) == 1:\n",
    "            if ',  ' in part['text'][0]:\n",
    "                part['text'] = re.split(r',  +', part['text'][0].strip())\n",
    "            else:\n",
    "                part['text'] = re.split(r'\\s{3,}', part['text'][0].strip())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db40369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_ms(str_time):\n",
    "    if isinstance(str_time, float):\n",
    "        return str_time * 1000\n",
    "    time = str_time.split(':')\n",
    "    if len(time) == 3:\n",
    "        return (int(time[2]) + int(time[1]) * 60 + int(time[0]) * 3600) * 1000\n",
    "    else:\n",
    "        return (int(time[1]) + int(time[0]) * 60) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb309d93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def define_time(df, max_time):\n",
    "    curr_time_start = 0\n",
    "\n",
    "    for i, rep in enumerate(df):\n",
    "        rep['problems'] = []\n",
    "        if rep['time'] == 'UNK':\n",
    "            if i == len(df) - 1:\n",
    "                time = max_time * 1000\n",
    "            else:\n",
    "                x = i + 1\n",
    "                if x >= len(df):\n",
    "                    time = curr_time_start + (max_time * 1000 - curr_time_start) / x\n",
    "                else:\n",
    "                    while (time := df[x]['time']) == 'UNK':\n",
    "                        x += 1\n",
    "                        if x >= len(df):\n",
    "                            time = curr_time_start + (max_time * 1000 - curr_time_start) / x\n",
    "                            break\n",
    "                    else:\n",
    "                        n_unk = x - i\n",
    "\n",
    "                        time = curr_time_start + (time_to_ms(time) - curr_time_start) / (n_unk + 1)\n",
    "            rep['problems'].append('TIME')\n",
    "        else:\n",
    "            time = time_to_ms(rep['time'])\n",
    "        rep['time'] = time + 100\n",
    "        rep['start_time'] = curr_time_start + 500\n",
    "\n",
    "        if len(rep['text']) < 2:\n",
    "            rep['problems'].append('ONE PART')\n",
    "        elif len(rep['text']) > 2:\n",
    "            rep['problems'].append('MORE THAN TWO PARTS')\n",
    "\n",
    "        curr_time_start = time\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "190b5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_for_elan(df, add_time=0):\n",
    "\n",
    "    transcriptions = []\n",
    "    translations = []\n",
    "    comments = []\n",
    "    problems = []\n",
    "    times = {}\n",
    "    \n",
    "    i = 1\n",
    "    k = 1\n",
    "    for chunk in df:\n",
    "        if not chunk['text']:\n",
    "            continue\n",
    "            \n",
    "        if int(chunk['time']) + add_time in times:\n",
    "            times[int(chunk['start_time']) + 500 + add_time] = k\n",
    "            times[int(chunk['time']) + 500 + add_time] = k + 1\n",
    "        else:\n",
    "            times[int(chunk['start_time']) + add_time] = k\n",
    "            times[int(chunk['time']) + add_time] = k + 1\n",
    "\n",
    "        transcriptions.append({\n",
    "            'id': i,\n",
    "            'start_time': k,\n",
    "            'time': k + 1,\n",
    "            'text': chunk['text'][0].replace('<', '[').replace('>', ']')\n",
    "        })\n",
    "        translations.append({\n",
    "            'id': i + 1,\n",
    "            'start_time': k,\n",
    "            'time': k + 1,\n",
    "            'text': ' '.join(chunk['text'][1:]).replace('<', '[').replace('>', ']') if len(chunk['text']) > 1 else ''\n",
    "        })\n",
    "        comments.append({\n",
    "            'id': i + 2,\n",
    "            'start_time': k,\n",
    "            'time': k + 1,\n",
    "            'text': chunk.get('comment', '')\n",
    "        })\n",
    "        problems.append({\n",
    "            'id': i + 3,\n",
    "            'start_time': k,\n",
    "            'time': k + 1,\n",
    "            'text': ' and '.join(chunk.get('problems', []))\n",
    "        })\n",
    "        i += 4\n",
    "        k += 2\n",
    "    return transcriptions, translations, comments, problems, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c4eaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_jinja_html(fname, **context):\n",
    "    return jinja2.Environment(\n",
    "        loader=jinja2.FileSystemLoader('.')\n",
    "    ).get_template(fname).render(context)\n",
    "\n",
    "\n",
    "def create_template(filename, transcriptions, translations, comments, problems, times):\n",
    "    s = render_jinja_html('eaf_template.eaf',\n",
    "                          filename=filename,\n",
    "                          cur_time=datetime.datetime.now().isoformat(),\n",
    "                          transcriptions=transcriptions,\n",
    "                          translations=translations,\n",
    "                          comments = comments,\n",
    "                          problems = problems,\n",
    "                          times = times.items()\n",
    "                         )\n",
    "    rxEmptyLines = re.compile('\\n\\s*\\n', flags=re.DOTALL)\n",
    "    s = rxEmptyLines.sub('\\n', s)\n",
    "    fnameOut = 'eafs/' + filename[:-4] + '.eaf'\n",
    "    fOut = open(fnameOut, 'w', encoding='utf-8')\n",
    "    fOut.write(s)\n",
    "    fOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "407d8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    'alut-txn-2008-161.docx': 'alut-2008-txn161-VVV-0125.wav',\n",
    "    'alut-txn-2008-113-14.docx': 'alut-txn-2008-113-VVV-detstvo-2007.WAV',\n",
    "    'alut-txn-2008-162.docx': 'alut-2008-txn162-VVV-0127.wav',\n",
    "    'alut-txn-2009-171.docx': 'alut-2009-txn-171_171R_172R-IOK-1-0001.wav',\n",
    "    'alut-txn-2009-176.docx': 'alut-2009-txn-175_177-IOK-4-0004.wav',\n",
    "    'alut-txn-2009-178.docx': 'alut-2009-txn-178_178R-RUR-muxomory-0228.wav',\n",
    "    'alut-txn-2009-180.docx': 'alut-2009-txn-180-DAM-1-0009.wav',\n",
    "    'alut-txn-2009-181.docx': 'alut-2009-txn-181-DAM-2-0010.wav',\n",
    "    'alut-txn-2008-111.docx': 'alut-txn-2008-108_112-VVV-2006.WAV',\n",
    "    'alut-txn-2008-123.docx': 'alut-txn-2008-123-DAM-1-0106.WAV',\n",
    "    'alut-txn-2008-126-4.docx': 'alut-txn-2008-126-DAM-4-0109.WAV',\n",
    "    'alut-txn-2008-127-5.docx': 'alut-txn-2008-127-DAM-5-2009.WAV',\n",
    "    'alut-txn-2008-128-6.docx': 'alut-txn-2008-128-DAM-6-2010.WAV'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb5a8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        if para.text.strip().strip(punctuation):\n",
    "            fullText.append(para.text.strip())\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3de79262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2eaf(filename, add_time=0):\n",
    "    max_time = librosa.get_duration(path='eafs/' + MAPPING[filename])\n",
    "    text = getText('texts/' + filename)\n",
    "    lines = split_text_by_language(text.splitlines())\n",
    "    df = parse_lines(lines)\n",
    "    df = parse_problem_parts(df)\n",
    "    df = define_time(df, max_time)\n",
    "    transcriptions, translations, comments, problems, times = make_data_for_elan(df, add_time)\n",
    "    \n",
    "#     return times\n",
    "    \n",
    "    audio = MAPPING[filename]\n",
    "    \n",
    "    create_template(audio, transcriptions, translations, comments, problems, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc84bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_docs = [\n",
    "    'alut-txn-2008-161.docx',\n",
    "    'alut-txn-2009-171.docx',\n",
    "    'alut-txn-2009-178.docx',\n",
    "    'alut-txn-2009-180.docx',\n",
    "    'alut-txn-2009-181.docx',\n",
    "    'alut-txn-2008-127-5.docx',\n",
    "    'alut-txn-2008-128-6.docx',\n",
    "    'alut-txn-2008-162.docx',\n",
    "    'alut-txn-2008-113-14.docx',\n",
    "    'alut-txn-2009-176.docx',\n",
    "    'alut-txn-2008-126-4.docx'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "744a6c71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word2eaf('alut-txn-2008-126-4.docx', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "709cbfb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alut-txn-2008-161.docx\n",
      "alut-txn-2009-171.docx\n",
      "alut-txn-2009-178.docx\n",
      "alut-txn-2009-180.docx\n",
      "alut-txn-2009-181.docx\n",
      "alut-txn-2008-127-5.docx\n",
      "alut-txn-2008-128-6.docx\n",
      "alut-txn-2008-162.docx\n",
      "alut-txn-2008-113-14.docx\n",
      "alut-txn-2009-176.docx\n",
      "alut-txn-2008-126-4.docx\n"
     ]
    }
   ],
   "source": [
    "for doc in ok_docs:\n",
    "    print(doc)\n",
    "    word2eaf(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e6c3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2eaf('alut-txn-2008-111.docx', (27*60 + 6)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57c113f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2eaf('alut-txn-2008-123.docx', int((47*60 + 40)*1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
